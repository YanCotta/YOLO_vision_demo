# FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

## Projeto: Detec√ß√£o Customizada com YOLOv5

### Nome do grupo

FarmTech Vision Lab

## üë®‚Äçüéì Integrantes

- [Yan Pimentel Cotta - RM: 562836](https://www.linkedin.com/in/yan-cotta)
- [Jonas T V Fernandes - RM: 563027](https://www.linkedin.com/in/jonastadeufernandes)
- [Raphael da Silva - RM: 561452](https://www.linkedin.com/in/raphaelsilva-phael)
- [Raphael Dinelli Neto - RM: 562892](https://www.linkedin.com/in/raphael-dinelli-8a01b278/)
- [Levi Passos Silveira Marques - RM: 565557](https://www.linkedin.com/company/inova-fusca)

## üë©‚Äçüè´ Professores

### Tutor(a)

- [Leonardo Ruiz Orabona](https://www.linkedin.com/in/leonardoorabona)

### Coordenador(a)

- [Andr√© Godoi](https://www.linkedin.com/in/andregodoichiovato/)
 
## üìú Descri√ß√£o

Este projeto apresenta uma solu√ß√£o completa de vis√£o computacional desenvolvida para a FarmTech Solutions, englobando tr√™s entregas distintas que demonstram diferentes aspectos e t√©cnicas de detec√ß√£o e classifica√ß√£o de objetos utilizando Deep Learning.

### Entrega 1: Detec√ß√£o Customizada com YOLOv5
- Prova de conceito de vis√£o computacional utilizando YOLOv5 para detectar objetos customizados (`banana` e `fork`).
- Pipeline completo: coleta propriet√°ria de 80 imagens (40 por classe), rotulagem no Make Sense AI, treinamento em Google Colab, avalia√ß√£o quantitativa, valida√ß√£o qualitativa e documenta√ß√£o executiva.
- Tr√™s experimentos controlados:
  - **YOLOv5s com 30 √©pocas**: mAP@.50 de 0.393 (baseline inicial)
  - **YOLOv5s com 60 √©pocas**: mAP@.50 de 0.513 (melhora de 30,5%)
  - **YOLOv5m com 60 √©pocas**: mAP@.50 de 0.789 (modelo campe√£o, +53,8%)
- An√°lise aprofundada dos trade-offs entre acur√°cia e custo computacional, com foco em implica√ß√µes para deploy em ambientes cloud versus edge.
- Discuss√£o detalhada sobre limita√ß√µes de bounding boxes para objetos de geometria complexa e roadmap de evolu√ß√£o (segmenta√ß√£o, otimiza√ß√£o de hiperpar√¢metros, compress√£o de modelos).
- **Notebook**: [`notebooks/entregavel_1_fase6_cap1.ipynb`](notebooks/entregavel_1_fase6_cap1.ipynb)
- **V√≠deo explicativo**: [https://www.youtube.com/watch?v=Z7gbPLNvm-4]

### Entrega 2: Compara√ß√£o YOLO vs CNN
- Estudo comparativo entre a arquitetura YOLOv5 (detec√ß√£o de objetos) e uma Rede Neural Convolucional customizada (classifica√ß√£o de imagens).
- Desenvolvimento de uma CNN do zero com arquitetura sequencial, incluindo camadas convolucionais, pooling, dropout e densas.
- Treinamento da CNN em dois cen√°rios: 30 √©pocas e 60 √©pocas, avaliando acur√°cia de treino e valida√ß√£o.
- An√°lise comparativa considerando:
  - Facilidade de uso e integra√ß√£o
  - Precis√£o e m√©tricas de desempenho
  - Tempo de treinamento e customiza√ß√£o
  - Tempo de infer√™ncia
- Conclus√£o: YOLOv5 demonstrou superioridade para tarefas de detec√ß√£o em tempo real, enquanto a CNN √© mais adequada para classifica√ß√£o pura.
- **Notebook**: [`notebooks/Entrega2_RaphaelDaSilva_RM561452_fase6_cap1.ipynb`](notebooks/Entrega2_RaphaelDaSilva_RM561452_fase6_cap1.ipynb)
- **V√≠deo explicativo**: [https://youtu.be/z1lbYlWnz9I]

### Ir Al√©m 2: Classifica√ß√£o Avan√ßada com Transfer Learning
- Pipeline avan√ßado de duas etapas combinando detec√ß√£o de objetos e classifica√ß√£o com transfer learning.
- **Abordagem 1 (Baseline)**: Classificador direto usando MobileNetV2 pr√©-treinado para classifica√ß√£o de imagens.
- **Abordagem 2 (Pipeline Integrado)**: Pr√©-processamento inteligente com YOLOv5 para identificar e recortar ROI (Regi√£o de Interesse), seguido de classifica√ß√£o com MobileNetV2.
- Resultados experimentais:
  - Baseline: 75% acur√°cia, 67.86% precis√£o, 100% recall
  - Pipeline Integrado: 87.50% acur√°cia (+12.50 pontos), 85.71% precis√£o (+17.86 pontos), 75% recall
- Valida√ß√£o da hip√≥tese de que o pr√©-processamento com detec√ß√£o melhora significativamente a acur√°cia e precis√£o da classifica√ß√£o.
- An√°lise de trade-offs entre confiabilidade (precis√£o) e abrang√™ncia (recall), com recomenda√ß√µes para diferentes contextos de aplica√ß√£o.
- **Notebook**: [`notebooks/ir_alem_opcao_2_fase_6_cap1.ipynb`](notebooks/ir_alem_opcao_2_fase_6_cap1.ipynb)
- **Documenta√ß√£o adicional**: [`README_IR_ALEM_2.md`](README_IR_ALEM_2.md)
- **V√≠deo explicativo**: [https://www.youtube.com/watch?v=csRnLQyvWsM]

### Documenta√ß√£o Integrada
- Relat√≥rio executivo detalhado: [`docs/report.md`](docs/report.md)
- Orienta√ß√µes do projeto: [`docs/orientation.md`](docs/orientation.md)
- Gr√°ficos comparativos, tabelas executivas e an√°lises textuais dispon√≠veis nos notebooks

## üíΩ Fontes de dados

- **Dataset propriet√°rio**: 80 imagens capturadas manualmente (40 imagens de `banana` e 40 imagens de `fork`).
- **Divis√£o estratificada**: 64 imagens para treino, 8 para valida√ß√£o, 8 para teste (propor√ß√£o 80/10/10).
- **Rotulagem**: Anota√ß√£o manual realizada no Make Sense AI com bounding boxes retangulares para compatibilidade com o formato YOLO.
- **Armazenamento**: Imagens e r√≥tulos armazenados no Google Drive para integra√ß√£o com Google Colab.
- **Variabilidade**: Dataset coletado com diversidade de √¢ngulos, ilumina√ß√£o e fundos para aumentar a robustez dos modelos.

## üìÅ Estrutura de pastas

```
YOLO_vision_demo/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ entregavel_1_fase6_cap1.ipynb              # Entrega 1: Detec√ß√£o YOLOv5
‚îÇ   ‚îú‚îÄ‚îÄ Entrega2_RaphaelDaSilva_RM561452_fase6_cap1.ipynb  # Entrega 2: YOLO vs CNN
‚îÇ   ‚îî‚îÄ‚îÄ ir_alem_opcao_2_fase_6_cap1.ipynb          # Ir Al√©m 2: Transfer Learning
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ orientation.md          # Enunciado oficial e requisitos do projeto
‚îÇ   ‚îî‚îÄ‚îÄ report.md              # Relat√≥rio executivo detalhado (Entrega 1)
‚îú‚îÄ‚îÄ assets/                    # Logotipos e materiais visuais de apoio
‚îú‚îÄ‚îÄ README.md                  # Este arquivo - vis√£o geral do projeto
‚îî‚îÄ‚îÄ README_IR_ALEM_2.md       # Documenta√ß√£o espec√≠fica do "Ir Al√©m 2"
```

## üîß Como executar o c√≥digo

### Entrega 1: Detec√ß√£o YOLOv5
1. Abra o notebook [`notebooks/entregavel_1_fase6_cap1.ipynb`](notebooks/entregavel_1_fase6_cap1.ipynb) no Google Colab.
2. Monte o Google Drive e ajuste os caminhos conforme necess√°rio (`/content/drive/MyDrive/PBL6_Project_YOLO/`).
3. Execute as c√©lulas sequencialmente:
   - Clonagem do reposit√≥rio YOLOv5
   - Instala√ß√£o de depend√™ncias
   - Montagem e configura√ß√£o do dataset
   - Treinamentos dos tr√™s experimentos (Exp_30_Epocas, Exp_60_Epocas, Exp_60_Epocas_Medium)
   - Infer√™ncias no conjunto de teste
4. Monitore os resultados em:
   - `runs/train/Exp_30_Epocas` - Primeiro experimento (YOLOv5s, 30 √©pocas)
   - `runs/train/Exp_60_Epocas` - Segundo experimento (YOLOv5s, 60 √©pocas)
   - `runs/train/Exp_60_Epocas_Medium` - Terceiro experimento (YOLOv5m, 60 √©pocas)
   - `runs/detect/Teste_Final` - Resultados da infer√™ncia
5. Exporte os gr√°ficos comparativos gerados:
   - `comparacao_curvas_aprendizado.png`
   - `comparativo_final_barras.png`
   - `comparacao_curvas_de_perda.png`
   - `tabela_comparativa_final.png`

### Entrega 2: Compara√ß√£o YOLO vs CNN
1. Abra o notebook [`notebooks/Entrega2_RaphaelDaSilva_RM561452_fase6_cap1.ipynb`](notebooks/Entrega2_RaphaelDaSilva_RM561452_fase6_cap1.ipynb) no Google Colab.
2. Monte o Google Drive com o dataset j√° preparado.
3. Execute as se√ß√µes do notebook:
   - Configura√ß√£o e importa√ß√µes
   - Treinamento do modelo YOLOv5 tradicional
   - Constru√ß√£o e treinamento da CNN customizada (30 e 60 √©pocas)
   - An√°lise visual dos resultados de ambos os modelos
   - Compara√ß√£o de m√©tricas e conclus√µes
4. Revise os gr√°ficos de perda, acur√°cia e exemplos de infer√™ncia gerados.

### Ir Al√©m 2: Transfer Learning Avan√ßado
1. Abra o notebook [`notebooks/ir_alem_opcao_2_fase_6_cap1.ipynb`](notebooks/ir_alem_opcao_2_fase_6_cap1.ipynb) no Google Colab.
2. Monte o Google Drive e configure os caminhos do dataset.
3. Execute as se√ß√µes do notebook:
   - Setup do ambiente e prepara√ß√£o dos dados
   - **Abordagem 1**: Treinamento do classificador baseline com MobileNetV2
   - **Abordagem 2**: Implementa√ß√£o do pipeline integrado (YOLOv5 + MobileNetV2)
   - An√°lise comparativa entre as duas abordagens
   - Visualiza√ß√µes e conclus√µes
4. Analise os resultados comparativos de acur√°cia, precis√£o e recall entre as abordagens.

### Observa√ß√µes Gerais
- Todos os notebooks foram desenvolvidos para execu√ß√£o no **Google Colab** com GPU T4.
- √â necess√°rio ter uma conta Google com acesso ao Google Drive para armazenamento do dataset.
- Os notebooks cont√™m c√©lulas Markdown detalhadas explicando cada etapa do processo.
- Recomenda-se executar as c√©lulas sequencialmente para evitar erros de depend√™ncias.

## üóÉ Hist√≥rico de lan√ßamentos

### Entregas Principais
- **2025-10-10 - Entrega 1**: Prova de conceito inicial com YOLOv5, incluindo tr√™s experimentos comparativos (YOLOv5s 30 √©pocas, YOLOv5s 60 √©pocas, YOLOv5m 60 √©pocas), documenta√ß√£o executiva completa e an√°lise de trade-offs para deploy em diferentes ambientes.

- **2025-10-13 - Entrega 2**: Estudo comparativo entre YOLOv5 e CNN customizada, avaliando diferentes arquiteturas para detec√ß√£o versus classifica√ß√£o de objetos, incluindo an√°lise de desempenho, facilidade de uso e aplicabilidade.

- **2025-10-15 - Ir Al√©m 2**: Pipeline avan√ßado integrando YOLOv5 para detec√ß√£o e MobileNetV2 para classifica√ß√£o, demonstrando t√©cnicas de transfer learning e pr√©-processamento inteligente com an√°lise comparativa quantitativa.

### Atualiza√ß√µes de Documenta√ß√£o
- **2025-10-15**: Atualiza√ß√£o completa do README.md e docs/report.md refletindo o escopo integral do projeto com todas as tr√™s entregas em portugu√™s brasileiro.

## üìã Licen√ßa

Este reposit√≥rio segue o modelo [MODELO GIT FIAP](https://github.com/agodoi/template) licenciado sob [Creative Commons Attribution 4.0 International](http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1).
